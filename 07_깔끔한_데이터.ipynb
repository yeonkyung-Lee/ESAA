{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. 깔끔한 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-1. 열과 피벗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__넓은 데이터__\n",
    "열 이름이 어떤 값을 의미할 경우 열이 옆으로 길게 늘어선 형태가 된다. 이런 데이터를 '넓은 데이터'라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__melt 메서드__ 넓은 데이터에서 지정한 열의 데이터를 모두 행으로 정리해 준다.\n",
    "- __메서드 인자__\n",
    " - id_var : 위치를 유지할 열 지정\n",
    " - value_vars : 행으로 위치를 변경할 열 지정\n",
    " - var_name : 위치를 변경한 열 이름 지정\n",
    " - value_name : 위치를 변경한 열의 데이터를 저장할 열 이름 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt 메서드 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../ESAA/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    religion            variable  value\n",
      "0                   Agnostic               <$10k     27\n",
      "1                    Atheist               <$10k     12\n",
      "2                   Buddhist               <$10k     27\n",
      "3                   Catholic               <$10k    418\n",
      "4         Don’t know/refused               <$10k     15\n",
      "5           Evangelical Prot               <$10k    575\n",
      "6                      Hindu               <$10k      1\n",
      "7    Historically Black Prot               <$10k    228\n",
      "8          Jehovah's Witness               <$10k     20\n",
      "9                     Jewish               <$10k     19\n",
      "10             Mainline Prot               <$10k    289\n",
      "11                    Mormon               <$10k     29\n",
      "12                    Muslim               <$10k      6\n",
      "13                  Orthodox               <$10k     13\n",
      "14           Other Christian               <$10k      9\n",
      "15              Other Faiths               <$10k     20\n",
      "16     Other World Religions               <$10k      5\n",
      "17              Unaffiliated               <$10k    217\n",
      "18                  Agnostic             $10-20k     34\n",
      "19                   Atheist             $10-20k     27\n",
      "20                  Buddhist             $10-20k     21\n",
      "21                  Catholic             $10-20k    617\n",
      "22        Don’t know/refused             $10-20k     14\n",
      "23          Evangelical Prot             $10-20k    869\n",
      "24                     Hindu             $10-20k      9\n",
      "25   Historically Black Prot             $10-20k    244\n",
      "26         Jehovah's Witness             $10-20k     27\n",
      "27                    Jewish             $10-20k     19\n",
      "28             Mainline Prot             $10-20k    495\n",
      "29                    Mormon             $10-20k     40\n",
      "..                       ...                 ...    ...\n",
      "150                    Hindu               >150k     54\n",
      "151  Historically Black Prot               >150k     78\n",
      "152        Jehovah's Witness               >150k      6\n",
      "153                   Jewish               >150k    151\n",
      "154            Mainline Prot               >150k    634\n",
      "155                   Mormon               >150k     42\n",
      "156                   Muslim               >150k      6\n",
      "157                 Orthodox               >150k     46\n",
      "158          Other Christian               >150k     12\n",
      "159             Other Faiths               >150k     41\n",
      "160    Other World Religions               >150k      4\n",
      "161             Unaffiliated               >150k    258\n",
      "162                 Agnostic  Don't know/refused     96\n",
      "163                  Atheist  Don't know/refused     76\n",
      "164                 Buddhist  Don't know/refused     54\n",
      "165                 Catholic  Don't know/refused   1489\n",
      "166       Don’t know/refused  Don't know/refused    116\n",
      "167         Evangelical Prot  Don't know/refused   1529\n",
      "168                    Hindu  Don't know/refused     37\n",
      "169  Historically Black Prot  Don't know/refused    339\n",
      "170        Jehovah's Witness  Don't know/refused     37\n",
      "171                   Jewish  Don't know/refused    162\n",
      "172            Mainline Prot  Don't know/refused   1328\n",
      "173                   Mormon  Don't know/refused     69\n",
      "174                   Muslim  Don't know/refused     22\n",
      "175                 Orthodox  Don't know/refused     73\n",
      "176          Other Christian  Don't know/refused     18\n",
      "177             Other Faiths  Don't know/refused     71\n",
      "178    Other World Religions  Don't know/refused      8\n",
      "179             Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion') #religion은 고정\n",
    "print(pew_long)  #column이 variable에 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    religion              income  count\n",
      "0                   Agnostic               <$10k     27\n",
      "1                    Atheist               <$10k     12\n",
      "2                   Buddhist               <$10k     27\n",
      "3                   Catholic               <$10k    418\n",
      "4         Don’t know/refused               <$10k     15\n",
      "5           Evangelical Prot               <$10k    575\n",
      "6                      Hindu               <$10k      1\n",
      "7    Historically Black Prot               <$10k    228\n",
      "8          Jehovah's Witness               <$10k     20\n",
      "9                     Jewish               <$10k     19\n",
      "10             Mainline Prot               <$10k    289\n",
      "11                    Mormon               <$10k     29\n",
      "12                    Muslim               <$10k      6\n",
      "13                  Orthodox               <$10k     13\n",
      "14           Other Christian               <$10k      9\n",
      "15              Other Faiths               <$10k     20\n",
      "16     Other World Religions               <$10k      5\n",
      "17              Unaffiliated               <$10k    217\n",
      "18                  Agnostic             $10-20k     34\n",
      "19                   Atheist             $10-20k     27\n",
      "20                  Buddhist             $10-20k     21\n",
      "21                  Catholic             $10-20k    617\n",
      "22        Don’t know/refused             $10-20k     14\n",
      "23          Evangelical Prot             $10-20k    869\n",
      "24                     Hindu             $10-20k      9\n",
      "25   Historically Black Prot             $10-20k    244\n",
      "26         Jehovah's Witness             $10-20k     27\n",
      "27                    Jewish             $10-20k     19\n",
      "28             Mainline Prot             $10-20k    495\n",
      "29                    Mormon             $10-20k     40\n",
      "..                       ...                 ...    ...\n",
      "150                    Hindu               >150k     54\n",
      "151  Historically Black Prot               >150k     78\n",
      "152        Jehovah's Witness               >150k      6\n",
      "153                   Jewish               >150k    151\n",
      "154            Mainline Prot               >150k    634\n",
      "155                   Mormon               >150k     42\n",
      "156                   Muslim               >150k      6\n",
      "157                 Orthodox               >150k     46\n",
      "158          Other Christian               >150k     12\n",
      "159             Other Faiths               >150k     41\n",
      "160    Other World Religions               >150k      4\n",
      "161             Unaffiliated               >150k    258\n",
      "162                 Agnostic  Don't know/refused     96\n",
      "163                  Atheist  Don't know/refused     76\n",
      "164                 Buddhist  Don't know/refused     54\n",
      "165                 Catholic  Don't know/refused   1489\n",
      "166       Don’t know/refused  Don't know/refused    116\n",
      "167         Evangelical Prot  Don't know/refused   1529\n",
      "168                    Hindu  Don't know/refused     37\n",
      "169  Historically Black Prot  Don't know/refused    339\n",
      "170        Jehovah's Witness  Don't know/refused     37\n",
      "171                   Jewish  Don't know/refused    162\n",
      "172            Mainline Prot  Don't know/refused   1328\n",
      "173                   Mormon  Don't know/refused     69\n",
      "174                   Muslim  Don't know/refused     22\n",
      "175                 Orthodox  Don't know/refused     73\n",
      "176          Other Christian  Don't know/refused     18\n",
      "177             Other Faiths  Don't know/refused     71\n",
      "178    Other World Religions  Don't know/refused      8\n",
      "179             Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars=\"religion\", var_name='income', value_name='count')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../ESAA/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week',value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-2. 열 이름 관리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__split 메서드로 열 이름 분리__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## ebola 데이터 집합 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('../ESAA/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음과 같은 결과가 나오도록 melt 메서드 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "ebola_long=pd.melt(ebola,id_vars=['Date','Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`split`__ Cases_Guinea와 같이 2개 이상의 의미를 가지고 있는 열 이름은 밑줄('_')을 기준으로 Cases, Guinea와 같은 방법으로 분리할 수 있다. split 메서드는 기본적으로 공백을 기준으로 문자열을 자른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열 이름 분리하고 데이터프레임에 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split)) #variable_split에 저장된 자료형은 시리즈\n",
    "print(type(variable_split[0])) #시리즈에 저장된 값(열 이름)의 자료형은 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리스트의 0번째 인덱스에 담긴 문자열은 발병(Cases)/죽음(Deaths)\n",
    "- 1번째 인덱스에 담긴 문자열은 나라 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get 메서드__ 를 사용하여 0,1번째 인덱스의 데이터 한꺼번에 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 분리한 문자열을 status, country라는 열 이름으로 데이터 프레임에 추가하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "ebola_long['status']=status_values\n",
    "ebola_long['country']=country_values\n",
    "\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat 메서드를 응용하여 데이터프레임에 열 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_',expand=True) #expand=T는 결과물을 데이터프레임으로 만든다.\n",
    "variable_split.columns = ['status','country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split],axis=1) #axis=1 : 열 방향으로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value  status country  status country\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0   Cases  Guinea   Cases  Guinea\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0   Cases  Guinea   Cases  Guinea\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0   Cases  Guinea   Cases  Guinea\n",
      "3       1/2/2015  286  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0   Cases  Guinea   Cases  Guinea\n",
      "5     12/28/2014  281  Cases_Guinea  2706.0   Cases  Guinea   Cases  Guinea\n",
      "6     12/27/2014  280  Cases_Guinea  2695.0   Cases  Guinea   Cases  Guinea\n",
      "7     12/24/2014  277  Cases_Guinea  2630.0   Cases  Guinea   Cases  Guinea\n",
      "8     12/21/2014  273  Cases_Guinea  2597.0   Cases  Guinea   Cases  Guinea\n",
      "9     12/20/2014  272  Cases_Guinea  2571.0   Cases  Guinea   Cases  Guinea\n",
      "10    12/18/2014  271  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "11    12/14/2014  267  Cases_Guinea  2416.0   Cases  Guinea   Cases  Guinea\n",
      "12     12/9/2014  262  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "13     12/7/2014  260  Cases_Guinea  2292.0   Cases  Guinea   Cases  Guinea\n",
      "14     12/3/2014  256  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "15    11/30/2014  253  Cases_Guinea  2164.0   Cases  Guinea   Cases  Guinea\n",
      "16    11/28/2014  251  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "17    11/23/2014  246  Cases_Guinea  2134.0   Cases  Guinea   Cases  Guinea\n",
      "18    11/22/2014  245  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "19    11/18/2014  241  Cases_Guinea  2047.0   Cases  Guinea   Cases  Guinea\n",
      "20    11/16/2014  239  Cases_Guinea  1971.0   Cases  Guinea   Cases  Guinea\n",
      "21    11/15/2014  238  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "22    11/11/2014  234  Cases_Guinea  1919.0   Cases  Guinea   Cases  Guinea\n",
      "23    11/10/2014  233  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "24     11/9/2014  232  Cases_Guinea  1878.0   Cases  Guinea   Cases  Guinea\n",
      "25     11/8/2014  231  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "26     11/4/2014  227  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "27     11/3/2014  226  Cases_Guinea  1760.0   Cases  Guinea   Cases  Guinea\n",
      "28     11/2/2014  225  Cases_Guinea  1731.0   Cases  Guinea   Cases  Guinea\n",
      "29    10/31/2014  222  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "...          ...  ...           ...     ...     ...     ...     ...     ...\n",
      "1922   5/23/2014   62   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1923   5/12/2014   51   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1924   5/10/2014   49   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1925    5/7/2014   46   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1926    5/5/2014   44   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1927    5/3/2014   42   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1928    5/1/2014   40   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1929   4/26/2014   35   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1930   4/24/2014   33   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1931   4/23/2014   32   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1932   4/22/2014   31   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1933   4/21/2014   30   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1934   4/20/2014   29   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1935   4/17/2014   26   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1936   4/16/2014   25   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1937   4/15/2014   24   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1938   4/14/2014   23   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1939   4/11/2014   20   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1940    4/9/2014   18   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1941    4/7/2014   16   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1942    4/4/2014   13   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1943    4/1/2014   10   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1944   3/31/2014    9   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1945   3/29/2014    7   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1946   3/28/2014    6   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "\n",
      "[1952 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ebola_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-3 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt, pivot_table 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('../ESAA/weather.csv')\n",
    "print(weather.iloc[:5,:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열의 날짜 데이터 행으로 위치 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_melt=pd.melt(weather,id_vars=['id','year','month','element'],var_name='day',value_name='temp')\n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행과 열의 위치 변경하기\n",
    "##### : element의 value를 열로, temp를 value열의 데이터로 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pivot_table 메서드__ 데이터를 재구성해 자료의 집계나 평균과 같은 통계량을 정리한 피벗 테이블을 만든다. \n",
    "- __메서드 인자__\n",
    " - __index__ : 만들어지는 피벗테이블의 로우를 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __values__ : 집계하려는 컬럼 이름 혹은 이름의 리스트.\n",
    " - __columns__ : 만들어지는 피벗테이블의 컬럼을 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __aggfunc__ : 집계함수나 함수 리스트. 기본값은 'mean'\n",
    " - __fill_value__ : 결과테이블에서 누락된 값을 대체하기 위한 값\n",
    " - __dropna__ : True이면 모든 항목이 NA인 컬럼은 포함하지 않는다.\n",
    " - __margin__ : 부분합이나 총계를 담기 위한 로우/컬럼을 추가할지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d30  27.8  14.5\n",
      "             2     d11  29.7  13.4\n",
      "                   d2   27.3  14.4\n",
      "                   d23  29.9  10.7\n",
      "                   d3   24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부분합 구하기 : margins=True\n",
    "margins=True를 넘겨서 부분합을 포함시키면 All 컬럼과 All 로우가 추가되어 단일 줄 안에서 그룹 통계를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin    All\n",
      "id      year month day                   \n",
      "MX17004 2010 1     d30  27.8  14.5  21.15\n",
      "             2     d11  29.7  13.4  21.55\n",
      "                   d2   27.3  14.4  20.85\n",
      "                   d23  29.9  10.7  20.30\n",
      "                   d3   24.1  14.4  19.25\n",
      "             3     d10  34.5  16.8  25.65\n",
      "                   d16  31.1  17.6  24.35\n",
      "                   d5   32.1  14.2  23.15\n",
      "             4     d27  36.3  16.7  26.50\n",
      "             5     d27  33.2  18.2  25.70\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True  #all이라는 새로운 column이 생겼음.\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### margin에서 집계 함수 변경 : aggfunc = 'count', len\n",
    "집계함수에서 'count'나 len 함수는 그룹 크기의 교차일람표(총 개수나 빈도)를 반환한다. 'mean'등의 통계량 사용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin  All\n",
      "id      year month day                 \n",
      "MX17004 2010 1     d1      0     0  NaN\n",
      "                   d10     0     0  NaN\n",
      "                   d11     0     0  NaN\n",
      "                   d12     0     0  NaN\n",
      "                   d13     0     0  NaN\n",
      "                   d14     0     0  NaN\n",
      "                   d15     0     0  NaN\n",
      "                   d16     0     0  NaN\n",
      "                   d17     0     0  NaN\n",
      "                   d18     0     0  NaN\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='count'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치가 있다면 fill_value로 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin    All\n",
      "id      year month day                   \n",
      "MX17004 2010 1     d30  27.8  14.5  21.15\n",
      "             2     d11  29.7  13.4  21.55\n",
      "                   d2   27.3  14.4  20.85\n",
      "                   d23  29.9  10.7  20.30\n",
      "                   d3   24.1  14.4  19.25\n",
      "             3     d10  34.5  16.8  25.65\n",
      "                   d16  31.1  17.6  24.35\n",
      "                   d5   32.1  14.2  23.15\n",
      "             4     d27  36.3  16.7  26.50\n",
      "             5     d27  33.2  18.2  25.70\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))  #temp에 결측이 있으면 0으로 두고 계산함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'element'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6f5ee06d5733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweather_tidy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'element'"
     ]
    }
   ],
   "source": [
    "weather_tidy.element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year month  day  tmax  tmin    All\n",
      "0        MX17004  2010     1  d30  27.8  14.5  21.15\n",
      "1        MX17004  2010     2  d11  29.7  13.4  21.55\n",
      "2        MX17004  2010     2   d2  27.3  14.4  20.85\n",
      "3        MX17004  2010     2  d23  29.9  10.7  20.30\n",
      "4        MX17004  2010     2   d3  24.1  14.4  19.25\n"
     ]
    }
   ],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-4. 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌보드 차트의 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../ESAA/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### track이 Loser인 것만 모아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복 데이터가 많은 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터를 가진 열(year, artist, track, time) 새 데이터 프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_long[['year','artist','track','time']]\n",
    "print(billboard_songs.shape)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거 - drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)  #완전 똑같은 것은 제거하고 1개만 남김"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복을 제거한 데이터에 id(행 순서)추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "billboard_songs['id']=range(len(billboard_songs))\n",
    "print(billboard_songs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노래 정보와 주간 순위 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year','artist','track','time'])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  rating  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2    82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3    72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4    77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5    87.0   0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-5. 대용량 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__여러 개로 나누어진 데이터 불러오기__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 나누어 저장하면 용량이 작아져 저장이나 공유에 유용하다. 또는 매일 수집하는 주식 정보처럼 여러 개의 작은 데이터가 생성되기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴욕 택시 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ESAA/raw_data_urls.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8cd7f5d363b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../ESAA/raw_data_urls.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../ESAA/raw_data_urls.txt'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "\n",
    "# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "with open('../ESAA/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break \n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', '../data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 5개의 파일 한꺼번에 불러오기\n",
    "내려받은 파일은 data폴더에 'fhv_tripdata_YYYY_MM.csv'로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../ESAA\\\\fhv_tripdata_2015-01.csv', '../ESAA\\\\fhv_tripdata_2015-02.csv', '../ESAA\\\\fhv_tripdata_2015-03.csv', '../ESAA\\\\fhv_tripdata_2015-04.csv', '../ESAA\\\\fhv_tripdata_2015-05.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "nyc_taxi_data = glob.glob('../ESAA/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각각의 파일을 데이터 프레임으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘 불러왔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head(2))\n",
    "print(taxi2.head(2))\n",
    "print(taxi3.head(2))\n",
    "print(taxi4.head(2))\n",
    "print(taxi5.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 데이터의 행과 열 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2746033, 3)\n",
      "(3126401, 3)\n",
      "(3281427, 3)\n",
      "(3917789, 3)\n",
      "(4296067, 3)\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 꽤 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taxi1~5를 행 방향으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi = pd.concat([taxi1,taxi2,taxi3,taxi4,taxi5]) #axis=0 : 행방향\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5개의 csv 파일을 데이터 프레임으로 변환하여 리스트에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "print(len(list_taxi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "2               B00013  2015-01-01 01:23:00         NaN\n",
      "3               B00013  2015-01-01 01:44:00         NaN\n",
      "4               B00013  2015-01-01 02:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_taxi_df라는 리스트 안에 데이터 프레임이 저장되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트에 있는 5개의 데이터 프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 만든 taxi 데이터 프레임과 반복문을 이용한 taxi_loop_concat 데이터 프레임이 동일하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
