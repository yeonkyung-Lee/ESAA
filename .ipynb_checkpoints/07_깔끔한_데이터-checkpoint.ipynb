{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. 깔끔한 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-1. 열과 피벗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__넓은 데이터__\n",
    "열 이름이 어떤 값을 의미할 경우 열이 옆으로 길게 늘어선 형태가 된다. 이런 데이터를 '넓은 데이터'라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__melt 메서드__ 넓은 데이터에서 지정한 열의 데이터를 모두 행으로 정리해 준다.\n",
    "- __메서드 인자__\n",
    " - id_var : 위치를 유지할 열 지정\n",
    " - value_vars : 행으로 위치를 변경할 열 지정\n",
    " - var_name : 위치를 변경한 열 이름 지정\n",
    " - value_name : 위치를 변경한 열의 데이터를 저장할 열 이름 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt 메서드 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../ESAA/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pew.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_long = pd.melt(pew, id_vars=\"religion\", var_name='income', value_name='count')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('../ESAA/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week',value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-2. 열 이름 관리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__split 메서드로 열 이름 분리__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## ebola 데이터 집합 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebola.iloc[:5, [0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음과 같은 결과가 나오도록 melt 메서드 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`split`__ Cases_Guinea와 같이 2개 이상의 의미를 가지고 있는 열 이름은 밑줄('_')을 기준으로 Cases, Guinea와 같은 방법으로 분리할 수 있다. split 메서드는 기본적으로 공백을 기준으로 문자열을 자른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열 이름 분리하고 데이터프레임에 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(variable_split)) #variable_split에 저장된 자료형은 시리즈\n",
    "print(type(variable_split[0])) #시리즈에 저장된 값(열 이름)의 자료형은 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리스트의 0번째 인덱스에 담긴 문자열은 발병(Cases)/죽음(Deaths)\n",
    "- 1번째 인덱스에 담긴 문자열은 나라 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get 메서드__ 를 사용하여 0,1번째 인덱스의 데이터 한꺼번에 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 분리한 문자열을 status, country라는 열 이름으로 데이터 프레임에 추가하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_long['status']=status_values\n",
    "ebola_long['country']=country_values\n",
    "\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat 메서드를 응용하여 데이터프레임에 열 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_',expand=True) #expand=T는 결과물을 데이터프레임으로 만든다.\n",
    "variable_split.columns = ['status','country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split],axis=1) #axis=1 : 열 방향으로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebola_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-3 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt, pivot_table 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../data/weather.csv')\n",
    "print(weather.iloc[:5,:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열의 날짜 데이터 행으로 위치 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행과 열의 위치 변경하기\n",
    "##### : element의 value를 열로, temp를 value열의 데이터로 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pivot_table 메서드__ 데이터를 재구성해 자료의 집계나 평균과 같은 통계량을 정리한 피벗 테이블을 만든다. \n",
    "- __메서드 인자__\n",
    " - __index__ : 만들어지는 피벗테이블의 로우를 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __values__ : 집계하려는 컬럼 이름 혹은 이름의 리스트.\n",
    " - __columns__ : 만들어지는 피벗테이블의 컬럼을 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __aggfunc__ : 집계함수나 함수 리스트. 기본값은 'mean'\n",
    " - __fill_value__ : 결과테이블에서 누락된 값을 대체하기 위한 값\n",
    " - __dropna__ : True이면 모든 항목이 NA인 컬럼은 포함하지 않는다.\n",
    " - __margin__ : 부분합이나 총계를 담기 위한 로우/컬럼을 추가할지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부분합 구하기 : margins=True\n",
    "margins=True를 넘겨서 부분합을 포함시키면 All 컬럼과 All 로우가 추가되어 단일 줄 안에서 그룹 통계를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### margin에서 집계 함수 변경 : aggfunc = 'count', len\n",
    "집계함수에서 'count'나 len 함수는 그룹 크기의 교차일람표(총 개수나 빈도)를 반환한다. 'mean'등의 통계량 사용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='count'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치가 있다면 fill_value로 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy.element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-4. 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌보드 차트의 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### track이 Loser인 것만 모아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복 데이터가 많은 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터를 가진 열(year, artist, track, time) 새 데이터 프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs = billboard_long[['year','artist','track','time']]\n",
    "print(billboard_songs.shape)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거 - drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복을 제거한 데이터에 id(행 순서)추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs['id']=range(len(billboard_songs))\n",
    "print(billboard_songs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노래 정보와 주간 순위 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year','artist','track','time'])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-5. 대용량 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__여러 개로 나누어진 데이터 불러오기__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 나누어 저장하면 용량이 작아져 저장이나 공유에 유용하다. 또는 매일 수집하는 주식 정보처럼 여러 개의 작은 데이터가 생성되기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴욕 택시 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "\n",
    "# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break \n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', '../data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 5개의 파일 한꺼번에 불러오기\n",
    "내려받은 파일은 data폴더에 'fhv_tripdata_YYYY_MM.csv'로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "nyc_taxi_data = glob.glob('../data/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각각의 파일을 데이터 프레임으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘 불러왔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi1.head(2))\n",
    "print(taxi2.head(2))\n",
    "print(taxi3.head(2))\n",
    "print(taxi4.head(2))\n",
    "print(taxi5.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 데이터의 행과 열 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 꽤 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taxi1~5를 행 방향으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = pd.concat([taxi1,taxi2,taxi3,taxi4,taxi5]) #axis=0 : 행방향\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5개의 csv 파일을 데이터 프레임으로 변환하여 리스트에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "print(len(list_taxi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_taxi_df라는 리스트 안에 데이터 프레임이 저장되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트에 있는 5개의 데이터 프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 만든 taxi 데이터 프레임과 반복문을 이용한 taxi_loop_concat 데이터 프레임이 동일하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
